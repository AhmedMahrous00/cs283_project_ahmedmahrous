{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd090bb-8982-42c2-a316-44f912c1a8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T18:20:42.188359Z",
     "iopub.status.busy": "2024-05-10T18:20:42.188359Z",
     "iopub.status.idle": "2024-05-10T18:20:48.434999Z",
     "shell.execute_reply": "2024-05-10T18:20:48.434380Z",
     "shell.execute_reply.started": "2024-05-10T18:20:42.188359Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def read_csv_files_to_columns(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "    \n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for i, file in enumerate(csv_files, start=1):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Read CSV file with the 'High' header\n",
    "        df_temp = pd.read_csv(file_path, usecols=['High'])\n",
    "        # Rename the column to reflect its file origin\n",
    "        df_temp.rename(columns={'High': f'High_{i}'}, inplace=True)\n",
    "        combined_df = pd.concat([combined_df, df_temp], axis=1)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "pumpFolder = \"C:/Users/mahrouaa/CS283_Project/DataPump/CS283/new_1m_binance\"\n",
    "randomFolder = \"C:/Users/mahrouaa/CS283_Project/DataPump/CS283/random1m\"\n",
    "\n",
    "pump_df = read_csv_files_to_columns(pumpFolder)\n",
    "random_df = read_csv_files_to_columns(randomFolder)\n",
    "pump_df = pump_df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "random_df = random_df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "pump_df = pump_df.iloc[:, :466]\n",
    "random_df = random_df.iloc[:, :466]\n",
    "\n",
    "pump_series = pump_df.to_numpy().T\n",
    "random_series = random_df.to_numpy().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702df2ef-29e4-466c-b95f-99c9ac0e0ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T18:20:48.437017Z",
     "iopub.status.busy": "2024-05-10T18:20:48.437017Z",
     "iopub.status.idle": "2024-05-10T18:20:48.483065Z",
     "shell.execute_reply": "2024-05-10T18:20:48.482060Z",
     "shell.execute_reply.started": "2024-05-10T18:20:48.437017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High_1</th>\n",
       "      <th>High_2</th>\n",
       "      <th>High_3</th>\n",
       "      <th>High_4</th>\n",
       "      <th>High_5</th>\n",
       "      <th>High_6</th>\n",
       "      <th>High_7</th>\n",
       "      <th>High_8</th>\n",
       "      <th>High_9</th>\n",
       "      <th>High_10</th>\n",
       "      <th>...</th>\n",
       "      <th>High_457</th>\n",
       "      <th>High_458</th>\n",
       "      <th>High_459</th>\n",
       "      <th>High_460</th>\n",
       "      <th>High_461</th>\n",
       "      <th>High_462</th>\n",
       "      <th>High_463</th>\n",
       "      <th>High_464</th>\n",
       "      <th>High_465</th>\n",
       "      <th>High_466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.117347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.287449</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.117347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.287449</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.117347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.064439</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.287449</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.117347</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.112319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200758</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.064439</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.287449</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.112319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.180095</td>\n",
       "      <td>0.426049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.411417</td>\n",
       "      <td>0.217252</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.289079</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.337121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.443709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612069</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.207668</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.291221</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.407480</td>\n",
       "      <td>0.198083</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.291221</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.337121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.465784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.405512</td>\n",
       "      <td>0.217252</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.289079</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.536424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.421260</td>\n",
       "      <td>0.204473</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.289079</td>\n",
       "      <td>0.007246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       High_1    High_2  High_3    High_4    High_5    High_6    High_7  \\\n",
       "0    0.128713  0.240000    0.04  0.111111  0.174242  0.513514  0.069767   \n",
       "1    0.128713  0.243333    0.04  0.111111  0.200758  0.513514  0.093023   \n",
       "2    0.178218  0.240000    0.04  0.111111  0.200758  0.513514  0.069767   \n",
       "3    0.158416  0.240000    0.04  0.111111  0.200758  0.513514  0.069767   \n",
       "4    0.158416  0.240000    0.04  0.111111  0.200758  0.513514  0.069767   \n",
       "..        ...       ...     ...       ...       ...       ...       ...   \n",
       "995  0.366337  0.013333    0.10  0.500000  0.348485  0.000000  0.139535   \n",
       "996  0.366337  0.013333    0.12  0.500000  0.337121  0.000000  0.116279   \n",
       "997  0.366337  0.013333    0.12  0.500000  0.344697  0.000000  0.116279   \n",
       "998  0.366337  0.016667    0.12  0.500000  0.337121  0.000000  0.116279   \n",
       "999  0.366337  0.016667    0.12  0.500000  0.333333  0.000000  0.116279   \n",
       "\n",
       "       High_8    High_9   High_10  ...  High_457  High_458  High_459  \\\n",
       "0    0.235294  0.071090  0.006623  ...  0.017241  0.093079  0.015385   \n",
       "1    0.235294  0.071090  0.006623  ...  0.025862  0.093079  0.015385   \n",
       "2    0.235294  0.071090  0.006623  ...  0.025862  0.093079  0.015385   \n",
       "3    0.235294  0.071090  0.006623  ...  0.034483  0.064439  0.015385   \n",
       "4    0.235294  0.071090  0.006623  ...  0.043103  0.064439  0.015385   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.176471  0.180095  0.426049  ...  0.620690  0.085919  0.220000   \n",
       "996  0.176471  0.175355  0.443709  ...  0.612069  0.085919  0.218462   \n",
       "997  0.176471  0.175355  0.456954  ...  0.620690  0.085919  0.218462   \n",
       "998  0.176471  0.175355  0.465784  ...  0.620690  0.085919  0.218462   \n",
       "999  0.176471  0.175355  0.536424  ...  0.620690  0.085919  0.220000   \n",
       "\n",
       "     High_460  High_461  High_462  High_463  High_464  High_465  High_466  \n",
       "0    0.222672  0.011811  0.003195  0.117347  0.000000  0.014989  0.108696  \n",
       "1    0.287449  0.025591  0.003195  0.117347  0.000000  0.014989  0.108696  \n",
       "2    0.287449  0.027559  0.003195  0.117347  0.000000  0.014989  0.108696  \n",
       "3    0.287449  0.027559  0.003195  0.117347  0.004098  0.014989  0.112319  \n",
       "4    0.287449  0.027559  0.003195  0.112245  0.004098  0.014989  0.112319  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.101215  0.411417  0.217252  0.173469  0.250000  0.289079  0.010870  \n",
       "996  0.101215  0.409449  0.207668  0.178571  0.245902  0.291221  0.000000  \n",
       "997  0.101215  0.407480  0.198083  0.178571  0.245902  0.291221  0.000000  \n",
       "998  0.101215  0.405512  0.217252  0.173469  0.245902  0.289079  0.007246  \n",
       "999  0.101215  0.421260  0.204473  0.178571  0.245902  0.289079  0.007246  \n",
       "\n",
       "[1000 rows x 466 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a56e7a-a0fe-4e59-9a23-dcb6c911fa26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T18:20:48.486065Z",
     "iopub.status.busy": "2024-05-10T18:20:48.485153Z",
     "iopub.status.idle": "2024-05-10T18:20:48.493252Z",
     "shell.execute_reply": "2024-05-10T18:20:48.492748Z",
     "shell.execute_reply.started": "2024-05-10T18:20:48.486065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pump_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158151fe-2b94-440f-8635-18c5fef0ab0c",
   "metadata": {},
   "source": [
    "# Pump and non-pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abbcbe4-ad09-4808-b752-8c56273aee93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T18:20:48.498256Z",
     "iopub.status.busy": "2024-05-10T18:20:48.495256Z",
     "iopub.status.idle": "2024-05-10T18:20:51.362310Z",
     "shell.execute_reply": "2024-05-10T18:20:51.360304Z",
     "shell.execute_reply.started": "2024-05-10T18:20:48.498256Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'means_cross' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Mean:\u001b[39m\u001b[38;5;124m\"\u001b[39m, means[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Standard Deviation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stds[i])\n\u001b[1;32m---> 36\u001b[0m print_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-Group\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmeans_cross\u001b[49m, stds_cross)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'means_cross' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cityblock, cosine\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import pearsonr, wasserstein_distance, ks_2samp, moment, skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(series1, series2):\n",
    "    euclidean_distance = norm(series1 - series2)\n",
    "    manhattan_distance = cityblock(series1, series2)\n",
    "    cosine_sim = 1 - cosine(series1, series2)\n",
    "    correlation, _ = pearsonr(series1, series2)\n",
    "    emd = wasserstein_distance(series1, series2)\n",
    "    ks_stat, ks_pvalue = ks_2samp(series1, series2)\n",
    "    return euclidean_distance, manhattan_distance, cosine_sim, correlation, emd, ks_stat, ks_pvalue\n",
    "\n",
    "def calculate_group_metrics(group1, group2):\n",
    "    distances = []\n",
    "    for series1 in tqdm(group1):\n",
    "        for series2 in group2:\n",
    "            metrics = calculate_metrics(series1, series2)\n",
    "            distances.append(metrics)\n",
    "    distances = np.array(distances)\n",
    "    means = np.mean(distances, axis=0)\n",
    "    stds = np.std(distances, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def print_metrics(title, means, stds):\n",
    "    metrics_names = [\"Euclidean\", \"Manhattan\", \"Cosine Similarity\", \"Pearson Correlation\", \"Earth Mover's\", \"KS Statistic\"]\n",
    "    print(title + \" Averages and Standard Deviations:\")\n",
    "    for i, name in enumerate(metrics_names):\n",
    "        print(f\"{name}:\")\n",
    "        print(\"  Mean:\", means[i], \"  Standard Deviation:\", stds[i])\n",
    "\n",
    "print_metrics(\"Cross-Group\", means_cross, stds_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4bfce-26fe-4970-abde-b8a312d9d3c7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.365308Z",
     "iopub.status.idle": "2024-05-10T18:20:51.367309Z",
     "shell.execute_reply": "2024-05-10T18:20:51.367309Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.367309Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_moments(series):\n",
    "    return {\n",
    "        'mean': np.mean(series),\n",
    "        'variance': np.var(series),\n",
    "        'skewness': skew(series),\n",
    "        'kurtosis': kurtosis(series)\n",
    "    }\n",
    "\n",
    "def aggregate_moments(data):\n",
    "    moments_data = {'mean': [], 'variance': [], 'skewness': [], 'kurtosis': []}\n",
    "    \n",
    "    # Calculate moments for each time series\n",
    "    for series in data:\n",
    "        moments = calculate_moments(series)\n",
    "        for key in moments:\n",
    "            moments_data[key].append(moments[key])\n",
    "    \n",
    "    # Calculate averages and standard deviations for each moment\n",
    "    aggregated_moments = {}\n",
    "    for key in moments_data:\n",
    "        aggregated_moments[f'avg_{key}'] = np.mean(moments_data[key])\n",
    "        aggregated_moments[f'std_{key}'] = np.std(moments_data[key])\n",
    "    \n",
    "    return aggregated_moments\n",
    "\n",
    "# Calculate aggregated moments for both series\n",
    "aggregated_moments_pump = aggregate_moments(pump_series)\n",
    "aggregated_moments_random = aggregate_moments(random_series)\n",
    "\n",
    "# Print aggregated moments\n",
    "print(\"Aggregated Moments for Pump Series:\")\n",
    "for key, value in aggregated_moments_pump.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAggregated Moments for Random Series:\")\n",
    "for key, value in aggregated_moments_random.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0dfc9-42d6-419f-a567-18aae5df301e",
   "metadata": {},
   "source": [
    "# Real vs GAN vs VAE vs GP vs Diffusion generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795f2bf-9574-49c4-937c-fae431cb523c",
   "metadata": {},
   "source": [
    "## Real vs GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2eb432-c1f5-42d5-868b-0bd38ffe4ecd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.371310Z",
     "iopub.status.idle": "2024-05-10T18:20:51.372309Z",
     "shell.execute_reply": "2024-05-10T18:20:51.372309Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.372309Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Real\")\n",
    "print(type(pump_series))\n",
    "print(pump_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c17ad6-d3ea-431e-82dc-61ec9176ff96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.377309Z",
     "iopub.status.idle": "2024-05-10T18:20:51.379309Z",
     "shell.execute_reply": "2024-05-10T18:20:51.379309Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.379309Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim, output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def generate_sample(generator, input_size):\n",
    "\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(1, input_size).to(device)\n",
    "        generated_sample = generator(noise)\n",
    "        \n",
    "        plt.figure(figsize=(10, 2))\n",
    "        plt.plot(generated_sample.cpu().numpy().reshape(-1))\n",
    "        plt.title(\"Generated Sample\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "input_size = 100  \n",
    "hidden_dim = 256\n",
    "output_size = 1000 \n",
    "\n",
    "G = Generator(input_size, hidden_dim, output_size).to(device)\n",
    "G.load_state_dict(torch.load('C:/Users/mahrouaa/CS283_Project/DataPump/CS283/pumpGAN.pth'))\n",
    "\n",
    "G.eval()\n",
    "\n",
    "generate_sample(G, input_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3eaa89-7dcc-452c-b776-f6aeaf9173ab",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.381309Z",
     "iopub.status.idle": "2024-05-10T18:20:51.382816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.382816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.382816Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_multiple_samples(generator, input_size, num_samples):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, input_size).to(device)\n",
    "        generated_samples = generator(noise)\n",
    "        return generated_samples.cpu().numpy().T  # Transpose to make each series a column\n",
    "\n",
    "num_samples = 466\n",
    "generated_data = generate_multiple_samples(G, input_size, num_samples)\n",
    "\n",
    "df_generated = pd.DataFrame(generated_data)\n",
    "df_generated.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5364b6-9ed6-4499-b21c-ba10cf59749b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.386816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.388816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.388816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.388816Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_series = df_generated.to_numpy().T\n",
    "print(\"GAN\")\n",
    "print(type(gan_series))\n",
    "print(gan_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da3819-2507-40d3-bc8e-67c41d6d46d6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.391816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.391816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.391816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.391816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cityblock, cosine\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import pearsonr, wasserstein_distance, ks_2samp, moment, skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(series1, series2):\n",
    "    euclidean_distance = norm(series1 - series2)\n",
    "    manhattan_distance = cityblock(series1, series2)\n",
    "    cosine_sim = 1 - cosine(series1, series2)\n",
    "    correlation, _ = pearsonr(series1, series2)\n",
    "    emd = wasserstein_distance(series1, series2)\n",
    "    ks_stat, ks_pvalue = ks_2samp(series1, series2)\n",
    "    return euclidean_distance, manhattan_distance, cosine_sim, correlation, emd, ks_stat, ks_pvalue\n",
    "\n",
    "def calculate_group_metrics(group1, group2):\n",
    "    distances = []\n",
    "    for series1 in tqdm(group1):\n",
    "        for series2 in group2:\n",
    "            metrics = calculate_metrics(series1, series2)\n",
    "            distances.append(metrics)\n",
    "    distances = np.array(distances)\n",
    "    means = np.mean(distances, axis=0)\n",
    "    stds = np.std(distances, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def print_metrics(title, means, stds):\n",
    "    metrics_names = [\"Euclidean\", \"Manhattan\", \"Cosine Similarity\", \"Pearson Correlation\", \"Earth Mover's\", \"KS Statistic\"]\n",
    "    print(title + \" Averages and Standard Deviations:\")\n",
    "    for i, name in enumerate(metrics_names):\n",
    "        print(f\"{name}:\")\n",
    "        print(\"  Mean:\", means[i], \"  Standard Deviation:\", stds[i])\n",
    "\n",
    "# Calculate and print metrics\n",
    "means_cross, stds_cross = calculate_group_metrics(pump_series, gan_series)\n",
    "\n",
    "print_metrics(\"Cross-Group\", means_cross, stds_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351a970-4bcf-4686-b054-81a64ea5192d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.393815Z",
     "iopub.status.idle": "2024-05-10T18:20:51.394816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.394816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.394816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_moments(series):\n",
    "    return {\n",
    "        'mean': np.mean(series),\n",
    "        'variance': np.var(series),\n",
    "        'skewness': skew(series),\n",
    "        'kurtosis': kurtosis(series)\n",
    "    }\n",
    "\n",
    "def aggregate_moments(data):\n",
    "    moments_data = {'mean': [], 'variance': [], 'skewness': [], 'kurtosis': []}\n",
    "    \n",
    "    # Calculate moments for each time series\n",
    "    for series in data:\n",
    "        moments = calculate_moments(series)\n",
    "        for key in moments:\n",
    "            moments_data[key].append(moments[key])\n",
    "    \n",
    "    # Calculate averages and standard deviations for each moment\n",
    "    aggregated_moments = {}\n",
    "    for key in moments_data:\n",
    "        aggregated_moments[f'avg_{key}'] = np.mean(moments_data[key])\n",
    "        aggregated_moments[f'std_{key}'] = np.std(moments_data[key])\n",
    "    \n",
    "    return aggregated_moments\n",
    "\n",
    "# Calculate aggregated moments for both series\n",
    "aggregated_moments_pump = aggregate_moments(pump_series)\n",
    "aggregated_moments_random = aggregate_moments(gan_series)\n",
    "\n",
    "# Print aggregated moments\n",
    "print(\"Aggregated Moments for Pump Series:\")\n",
    "for key, value in aggregated_moments_pump.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAggregated Moments for Random Series:\")\n",
    "for key, value in aggregated_moments_random.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1ec25-81eb-4edb-ad01-7412f1bc5286",
   "metadata": {},
   "source": [
    "## Real vs VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94d5f7-2289-49ec-ad05-d38a13afbfb2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.401815Z",
     "iopub.status.idle": "2024-05-10T18:20:51.404815Z",
     "shell.execute_reply": "2024-05-10T18:20:51.404815Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.404815Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, dropout_rate=0.5):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, latent_size * 2)  \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "latent_size=64\n",
    "\n",
    "vae = VAE(input_size=1000, hidden_size=256, latent_size=64).to(device)\n",
    "vae.load_state_dict(torch.load('C:/Users/mahrouaa/CS283_Project/DataPump/CS283/pumpVAE.pth'))\n",
    "vae.eval()\n",
    "\n",
    "def generate_sample(vae, latent_size):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, latent_size).to(device)\n",
    "        generated_time_series = vae.decoder(z)\n",
    "        generated_time_series_cpu = generated_time_series.cpu()\n",
    "        generated_time_series_np = generated_time_series_cpu.squeeze().numpy()\n",
    "\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        plt.plot(generated_time_series_np)\n",
    "        plt.title(\"Generated Time Series\")\n",
    "        plt.show()\n",
    "\n",
    "# Generate a synthetic time series sample\n",
    "generate_sample(vae, latent_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cb860-8ae0-4f8a-821d-945e756d9978",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.406816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.406816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.406816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.406816Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_multiple_samples(vae, latent_size, num_samples):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_size).to(device)\n",
    "        generated_time_series = vae.decoder(z)\n",
    "        generated_time_series_cpu = generated_time_series.cpu()\n",
    "        return generated_time_series_cpu.numpy().T  # Transpose to make each series a column\n",
    "\n",
    "# Generate 466 synthetic time series\n",
    "num_samples = 466\n",
    "generated_data = generate_multiple_samples(vae, latent_size, num_samples)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_generated = pd.DataFrame(generated_data)\n",
    "df_generated.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9430d-9c7f-4c06-8e2c-81f44a314e41",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.407816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.408816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.407816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.407816Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_series = df_generated.to_numpy().T\n",
    "print(\"VAE\")\n",
    "print(type(vae_series))\n",
    "print(vae_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7a88e-354d-46c3-87f2-222678adbd0e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.408816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.410815Z",
     "shell.execute_reply": "2024-05-10T18:20:51.409816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.409816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cityblock, cosine\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import pearsonr, wasserstein_distance, ks_2samp, moment, skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(series1, series2):\n",
    "    euclidean_distance = norm(series1 - series2)\n",
    "    manhattan_distance = cityblock(series1, series2)\n",
    "    cosine_sim = 1 - cosine(series1, series2)\n",
    "    correlation, _ = pearsonr(series1, series2)\n",
    "    emd = wasserstein_distance(series1, series2)\n",
    "    ks_stat, ks_pvalue = ks_2samp(series1, series2)\n",
    "    return euclidean_distance, manhattan_distance, cosine_sim, correlation, emd, ks_stat, ks_pvalue\n",
    "\n",
    "def calculate_group_metrics(group1, group2):\n",
    "    distances = []\n",
    "    for series1 in tqdm(group1):\n",
    "        for series2 in group2:\n",
    "            metrics = calculate_metrics(series1, series2)\n",
    "            distances.append(metrics)\n",
    "    distances = np.array(distances)\n",
    "    means = np.mean(distances, axis=0)\n",
    "    stds = np.std(distances, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def print_metrics(title, means, stds):\n",
    "    metrics_names = [\"Euclidean\", \"Manhattan\", \"Cosine Similarity\", \"Pearson Correlation\", \"Earth Mover's\", \"KS Statistic\"]\n",
    "    print(title + \" Averages and Standard Deviations:\")\n",
    "    for i, name in enumerate(metrics_names):\n",
    "        print(f\"{name}:\")\n",
    "        print(\"  Mean:\", means[i], \"  Standard Deviation:\", stds[i])\n",
    "\n",
    "# Calculate and print metrics\n",
    "means_cross, stds_cross = calculate_group_metrics(pump_series, vae_series)\n",
    "\n",
    "print_metrics(\"Cross-Group\", means_cross, stds_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74112e8-f429-400c-bf15-b3250245134f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.410815Z",
     "iopub.status.idle": "2024-05-10T18:20:51.411816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.410815Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.410815Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_moments(series):\n",
    "    return {\n",
    "        'mean': np.mean(series),\n",
    "        'variance': np.var(series),\n",
    "        'skewness': skew(series),\n",
    "        'kurtosis': kurtosis(series)\n",
    "    }\n",
    "\n",
    "def aggregate_moments(data):\n",
    "    moments_data = {'mean': [], 'variance': [], 'skewness': [], 'kurtosis': []}\n",
    "    \n",
    "    # Calculate moments for each time series\n",
    "    for series in data:\n",
    "        moments = calculate_moments(series)\n",
    "        for key in moments:\n",
    "            moments_data[key].append(moments[key])\n",
    "    \n",
    "    # Calculate averages and standard deviations for each moment\n",
    "    aggregated_moments = {}\n",
    "    for key in moments_data:\n",
    "        aggregated_moments[f'avg_{key}'] = np.mean(moments_data[key])\n",
    "        aggregated_moments[f'std_{key}'] = np.std(moments_data[key])\n",
    "    \n",
    "    return aggregated_moments\n",
    "\n",
    "# Calculate aggregated moments for both series\n",
    "aggregated_moments_pump = aggregate_moments(pump_series)\n",
    "aggregated_moments_random = aggregate_moments(vae_series)\n",
    "\n",
    "# Print aggregated moments\n",
    "print(\"Aggregated Moments for Pump Series:\")\n",
    "for key, value in aggregated_moments_pump.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAggregated Moments for Random Series:\")\n",
    "for key, value in aggregated_moments_random.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ff4ec-41bf-4098-a535-fe5f84d60e55",
   "metadata": {},
   "source": [
    "## Real vs GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8a882-31c5-4939-a883-5733d70363f2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.415816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.418815Z",
     "shell.execute_reply": "2024-05-10T18:20:51.418815Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.418815Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "folder_path = r\"C:\\Users\\mahrouaa\\CS283_Project\\DataPump\\CS283\\new_1m_binance\"\n",
    "\n",
    "returns_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, usecols=['returns'])\n",
    "        returns_list.append(df)\n",
    "\n",
    "all_returns_df = pd.concat(returns_list, axis=1)\n",
    "all_returns_df = all_returns_df.drop(all_returns_df.index[0])\n",
    "all_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02fc95-c310-4aaf-95ac-d23f33b74c5e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.420817Z",
     "iopub.status.idle": "2024-05-10T18:20:51.420817Z",
     "shell.execute_reply": "2024-05-10T18:20:51.420817Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.420817Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_vector = all_returns_df.mean(axis=1)\n",
    "stdev_vector = all_returns_df.std(axis=1)\n",
    "\n",
    "df_generated = pd.DataFrame()\n",
    "\n",
    "initial_price=100\n",
    "num_series=466\n",
    "\n",
    "for series_idx in range(num_series):\n",
    "    return_vector = np.random.normal(mean_vector, stdev_vector)\n",
    "    price_vector = [initial_price]\n",
    "    \n",
    "    for ret in return_vector:\n",
    "        new_price = price_vector[-1] * (1 + (ret / 100))\n",
    "        price_vector.append(new_price)\n",
    "    \n",
    "    df_generated[f'Series_{series_idx+1}'] = price_vector\n",
    "\n",
    "df_generated.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818cc36-7e8a-4b31-89cd-3596fc63d2fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.421816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.421816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.421816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.421816Z"
    }
   },
   "outputs": [],
   "source": [
    "gp_series = df_generated.to_numpy().T\n",
    "print(\"GP\")\n",
    "print(type(gp_series))\n",
    "print(gp_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a368ab9-fead-4abc-a2ad-9453fab297bc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.423816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.424816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.423816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.423816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cityblock, cosine\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import pearsonr, wasserstein_distance, ks_2samp, moment, skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(series1, series2):\n",
    "    euclidean_distance = norm(series1 - series2)\n",
    "    manhattan_distance = cityblock(series1, series2)\n",
    "    cosine_sim = 1 - cosine(series1, series2)\n",
    "    correlation, _ = pearsonr(series1, series2)\n",
    "    emd = wasserstein_distance(series1, series2)\n",
    "    ks_stat, ks_pvalue = ks_2samp(series1, series2)\n",
    "    return euclidean_distance, manhattan_distance, cosine_sim, correlation, emd, ks_stat, ks_pvalue\n",
    "\n",
    "def calculate_group_metrics(group1, group2):\n",
    "    distances = []\n",
    "    for series1 in tqdm(group1):\n",
    "        for series2 in group2:\n",
    "            metrics = calculate_metrics(series1, series2)\n",
    "            distances.append(metrics)\n",
    "    distances = np.array(distances)\n",
    "    means = np.mean(distances, axis=0)\n",
    "    stds = np.std(distances, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def print_metrics(title, means, stds):\n",
    "    metrics_names = [\"Euclidean\", \"Manhattan\", \"Cosine Similarity\", \"Pearson Correlation\", \"Earth Mover's\", \"KS Statistic\"]\n",
    "    print(title + \" Averages and Standard Deviations:\")\n",
    "    for i, name in enumerate(metrics_names):\n",
    "        print(f\"{name}:\")\n",
    "        print(\"  Mean:\", means[i], \"  Standard Deviation:\", stds[i])\n",
    "\n",
    "# Calculate and print metrics\n",
    "means_cross, stds_cross = calculate_group_metrics(pump_series, gp_series)\n",
    "\n",
    "print_metrics(\"Cross-Group\", means_cross, stds_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66240289-5030-4ad9-9515-000457287d2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.425816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.425816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.425816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.425816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_moments(series):\n",
    "    return {\n",
    "        'mean': np.mean(series),\n",
    "        'variance': np.var(series),\n",
    "        'skewness': skew(series),\n",
    "        'kurtosis': kurtosis(series)\n",
    "    }\n",
    "\n",
    "def aggregate_moments(data):\n",
    "    moments_data = {'mean': [], 'variance': [], 'skewness': [], 'kurtosis': []}\n",
    "    \n",
    "    # Calculate moments for each time series\n",
    "    for series in data:\n",
    "        moments = calculate_moments(series)\n",
    "        for key in moments:\n",
    "            moments_data[key].append(moments[key])\n",
    "    \n",
    "    # Calculate averages and standard deviations for each moment\n",
    "    aggregated_moments = {}\n",
    "    for key in moments_data:\n",
    "        aggregated_moments[f'avg_{key}'] = np.mean(moments_data[key])\n",
    "        aggregated_moments[f'std_{key}'] = np.std(moments_data[key])\n",
    "    \n",
    "    return aggregated_moments\n",
    "\n",
    "# Calculate aggregated moments for both series\n",
    "aggregated_moments_pump = aggregate_moments(pump_series)\n",
    "aggregated_moments_random = aggregate_moments(gp_series)\n",
    "\n",
    "# Print aggregated moments\n",
    "print(\"Aggregated Moments for Pump Series:\")\n",
    "for key, value in aggregated_moments_pump.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAggregated Moments for Random Series:\")\n",
    "for key, value in aggregated_moments_random.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc25ec-b507-4385-a1f7-3fab49a4ede0",
   "metadata": {},
   "source": [
    "## Real vs Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e9f4d-5e4b-454c-b1e5-5a2b860bde63",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.427816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.428817Z",
     "shell.execute_reply": "2024-05-10T18:20:51.428817Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.428817Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\mahrouaa\\\\Downloads\\\\generated_time_series.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "sampled_data = data.sample(466, random_state=42)\n",
    "\n",
    "df_generated = sampled_data\n",
    "new_column_names = [f\"Gen_{i+1}\" for i in range(df_generated.shape[1])]\n",
    "df_generated.columns = new_column_names\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_generated = pd.DataFrame(scaler.fit_transform(df_generated.T))\n",
    "\n",
    "df_generated.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1a553-831d-4c4f-b6da-e5bca81d504a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.429816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.429816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.429816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.429816Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_series = df_generated.to_numpy().T\n",
    "print(\"Diffusion\")\n",
    "print(type(diff_series))\n",
    "print(diff_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f6aa7-c1b3-44bd-8c89-95760c5d74e9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.430816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.430816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.430816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.430816Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cityblock, cosine\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import pearsonr, wasserstein_distance, ks_2samp, moment, skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(series1, series2):\n",
    "    euclidean_distance = norm(series1 - series2)\n",
    "    manhattan_distance = cityblock(series1, series2)\n",
    "    cosine_sim = 1 - cosine(series1, series2)\n",
    "    correlation, _ = pearsonr(series1, series2)\n",
    "    emd = wasserstein_distance(series1, series2)\n",
    "    ks_stat, ks_pvalue = ks_2samp(series1, series2)\n",
    "    return euclidean_distance, manhattan_distance, cosine_sim, correlation, emd, ks_stat, ks_pvalue\n",
    "\n",
    "def calculate_group_metrics(group1, group2):\n",
    "    distances = []\n",
    "    for series1 in tqdm(group1):\n",
    "        for series2 in group2:\n",
    "            metrics = calculate_metrics(series1, series2)\n",
    "            distances.append(metrics)\n",
    "    distances = np.array(distances)\n",
    "    means = np.mean(distances, axis=0)\n",
    "    stds = np.std(distances, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "def print_metrics(title, means, stds):\n",
    "    metrics_names = [\"Euclidean\", \"Manhattan\", \"Cosine Similarity\", \"Pearson Correlation\", \"Earth Mover's\", \"KS Statistic\"]\n",
    "    print(title + \" Averages and Standard Deviations:\")\n",
    "    for i, name in enumerate(metrics_names):\n",
    "        print(f\"{name}:\")\n",
    "        print(\"  Mean:\", means[i], \"  Standard Deviation:\", stds[i])\n",
    "\n",
    "# Calculate and print metrics\n",
    "means_cross, stds_cross = calculate_group_metrics(pump_series, diff_series)\n",
    "\n",
    "print_metrics(\"Cross-Group\", means_cross, stds_cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e78cf-003a-42fb-9f48-2f6885d1e89d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-10T18:20:51.431816Z",
     "iopub.status.idle": "2024-05-10T18:20:51.432816Z",
     "shell.execute_reply": "2024-05-10T18:20:51.432816Z",
     "shell.execute_reply.started": "2024-05-10T18:20:51.432816Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_moments(series):\n",
    "    return {\n",
    "        'mean': np.mean(series),\n",
    "        'variance': np.var(series),\n",
    "        'skewness': skew(series),\n",
    "        'kurtosis': kurtosis(series)\n",
    "    }\n",
    "\n",
    "def aggregate_moments(data):\n",
    "    moments_data = {'mean': [], 'variance': [], 'skewness': [], 'kurtosis': []}\n",
    "    \n",
    "    # Calculate moments for each time series\n",
    "    for series in data:\n",
    "        moments = calculate_moments(series)\n",
    "        for key in moments:\n",
    "            moments_data[key].append(moments[key])\n",
    "    \n",
    "    # Calculate averages and standard deviations for each moment\n",
    "    aggregated_moments = {}\n",
    "    for key in moments_data:\n",
    "        aggregated_moments[f'avg_{key}'] = np.mean(moments_data[key])\n",
    "        aggregated_moments[f'std_{key}'] = np.std(moments_data[key])\n",
    "    \n",
    "    return aggregated_moments\n",
    "\n",
    "# Calculate aggregated moments for both series\n",
    "aggregated_moments_pump = aggregate_moments(pump_series)\n",
    "aggregated_moments_random = aggregate_moments(diff_series)\n",
    "\n",
    "# Print aggregated moments\n",
    "print(\"Aggregated Moments for Pump Series:\")\n",
    "for key, value in aggregated_moments_pump.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAggregated Moments for Random Series:\")\n",
    "for key, value in aggregated_moments_random.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
